{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pytorch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Connect torch to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency 1 is \"120000000\"\n",
      "Frequency 2 is \"160000000\"\n",
      "Frequency 3 is \"90000000\"\n",
      "Frequency 4 is \"70000000\"\n",
      "Frequency 5 is \"100000000\"\n",
      "Frequency 6 is \"140000000\"\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/dataset_india_big.csv')\n",
    "\n",
    "# Pick a \n",
    "\n",
    "# Convert to numpy arrays\n",
    "nn_input = []\n",
    "frequencies = []\n",
    "\n",
    "counter = 1\n",
    "min_length = float('inf')\n",
    "\n",
    "# Split each frequency into a list of data for input to the neural network\n",
    "for frequency in df['Frequency'].unique():\n",
    "    print(f'Frequency {counter} is \"{frequency}\"')\n",
    "    frequencies.append(frequency)\n",
    "    counter += 1\n",
    "    \n",
    "    frequency_data = df[df['Frequency'] == frequency]['Signal Strength'].values\n",
    "    nn_input.append(frequency_data)\n",
    "    \n",
    "    if len(frequency_data) < min_length:\n",
    "        min_length = len(frequency_data)\n",
    "        \n",
    "# Truncate all data to the length of the shortest frequency\n",
    "for i in range(len(nn_input)):\n",
    "    nn_input[i] = nn_input[i][:min_length]\n",
    "\n",
    "# Place data in numpy array\n",
    "nn_input = np.array(nn_input)\n",
    "\n",
    "nn_input = nn_input.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of input variables\n",
    "\n",
    "- `input_size` is the amount of frequencies that have been measured\n",
    "- `hidden_size` is the amount of neurons in the hidden layer\n",
    "- `num_layers` is the amount of hidden layers that perform changes to get the correct prediction (chosen based on https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)\n",
    "- `output_size` is the amount of frequencies that are predicted, these are equal to the input since we want to see from the full prediction which frequency most likely has the lowest interference\n",
    "- `seq_length` is the amount of history that gets taken into account to make the new prediction\n",
    "- `num_epochs` is the amount of training rounds\n",
    "- `learning_rate` is the rate at which the weights of the hidden layers are updated to improve prediction results (cannot be too high because it might overshoot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27051, 6])\n"
     ]
    }
   ],
   "source": [
    "data = torch.FloatTensor(nn_input)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "# Neural network input\n",
    "input_size = data.shape[1]\n",
    "hidden_size = input_size\n",
    "num_layers = 1\n",
    "output_size = input_size\n",
    "seq_length = 12\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences and labels for training\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        label = data[i + seq_length]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return torch.stack(sequences), torch.stack(labels)\n",
    "\n",
    "# Parameters\n",
    "sequences, labels = create_sequences(data, seq_length)\n",
    "\n",
    "sequences = sequences.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)  # Hidden state\n",
    "        c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)  # Cell state\n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])  # Fully connected on the last output\n",
    "        return out\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, output_size, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6200, Loss: 1004.1107            "
     ]
    }
   ],
   "source": [
    "# Initialize loss\n",
    "loss = float('inf')\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "# Training loop\n",
    "while loss > 1000:\n",
    "    epoch += 1\n",
    "    \n",
    "    outputs = model(sequences)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        sys.stdout.write(f'\\rEpoch {epoch + 1}, Loss: {loss.item():.4f}            ')\n",
    "        sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next value:\n",
      "Frequency_1: -37.8916 dB | Frequency_2: -37.3596 dB | Frequency_3: -37.6615 dB | Frequency_4: -37.8767 dB | Frequency_5: -37.4292 dB | Frequency_6: -38.3638 dB\n",
      "\n",
      "The next likely available frequency is: 160000000\n"
     ]
    }
   ],
   "source": [
    "# Test prediction for the next value in the sequence\n",
    "with torch.no_grad():\n",
    "    test_input = data[-seq_length:].unsqueeze(0).to(device)  # Use the last 3 values\n",
    "    predicted_frequencies = model(test_input)\n",
    "    \n",
    "    results = predicted_frequencies[0].cpu().numpy()\n",
    "    \n",
    "    print(f'Predicted next value:')\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if i == len(results) - 1:\n",
    "            sys.stdout.write(f'Frequency_{i + 1}: {result:.4f} dB\\n')\n",
    "        else:\n",
    "            sys.stdout.write(f'Frequency_{i + 1}: {result:.4f} dB | ')\n",
    "    \n",
    "    # Post-prediction analysis\n",
    "    # Find the frequency that is predicted to be least occupied (based on some custom metric)\n",
    "    # Example: Choose frequency with the lowest predicted value (or you can apply a more specific condition)\n",
    "    best_frequency_index = torch.argmax(predicted_frequencies[-1, :])  # Last time step prediction\n",
    "    print(f\"\\nThe next likely available frequency is: {frequencies[best_frequency_index]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
